{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "\n",
    "Since wikipedia doesn't have dynamic elements, BeautifulSoup can be used for parsing. Moreover it has no bot-check so I can send 50 requests (amount of films) in 2 minutes.\n",
    "\n",
    "### Parser class\n",
    "The parser contains the main method parse() that finds the information about each film on the main page and films' pages. As a resu;t of this method, the class collects information and stores it in its variable 'films' - list of dictionaries. See the methods descriptions below.\n",
    "\n",
    "# Database design\n",
    "I chose the PostgreSQL database for storing my data. Firstly, I created the database 'wiki' from the console:\n",
    "```\n",
    "sudo -iu postgres\n",
    "createuser --interactive --pwprompt # superuser 12345678\n",
    "createdb wiki\n",
    "psql -l\n",
    "psql -U superuser -d wiki \n",
    "```\n",
    "\n",
    "I connect to it via psycopg2, created the 'films' table and insertes rows. I checked intermediate results via console using the following commands:\n",
    "```\n",
    "\\dt\n",
    "SELECT * FROM films;\n",
    "```\n",
    "The fields are the same as in the provided Assignment.pdf file, but additionally I have the 'poster' field with a url to the poster image (TEXT).\n",
    "\n",
    "\n",
    "Since some films have 2 or 3 directors and 2 countries, I changed the 'director' and 'country' fields type from TEXT to JSONB. I also added the 'poster' field for posters' urls.\n",
    "\n",
    "After the table creation I inserted the data from the ParserWikiPage variable parser one by one. Then I checked the correctness of insertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "\n",
    "URL = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "def get_soup(url=None):\n",
    "    \"\"\" Return a parsed tag tree of our Nobel prize page \"\"\"\n",
    "    if not url:\n",
    "        response = requests.get(URL, headers=HEADERS)\n",
    "    else:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code != 200:\n",
    "        print(response.status_code)\n",
    "    return BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "# soup = get_soup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParserWikiPage():\n",
    "    def __init__(self, main_url: str=None):\n",
    "        \"\"\" Init method.\n",
    "        Args:\n",
    "            main_url (str, optional): The default wiki paage with a table and links inside. Defaults to None.\n",
    "        \"\"\"\n",
    "        # during the main page's table parsing keep the links to films, which contain more information about movies\n",
    "        self.films_urls = []\n",
    "        if main_url:\n",
    "            self.URL: str = main_url\n",
    "        else:\n",
    "            self.URL: str = URL\n",
    "        # list of dictionaries, each contains film data (title, revenue, etc.)\n",
    "        self.films = None\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\" Main method. Demosntrates the logic: parse the main page first,\n",
    "            extract films' urls from it, and parse each film separately.\"\"\"\n",
    "        self.parse_main_page()\n",
    "        self.parse_films()\n",
    "        \n",
    "\n",
    "    def find_table(self, url: str=None, table_class: str='wikitable') -> bs4.element.Tag:\n",
    "        \"\"\" Method for finding desired tables on the page\n",
    "        Args:\n",
    "            url (str, optional): url of a page containing a table. Defaults to None.\n",
    "            table_class (str, optional): the 'name' of a searched table. Defaults to None.\n",
    "        Returns:\n",
    "            bs4.element.Tag: element <table> is returned.\n",
    "        \"\"\"\n",
    "        # if no url and table class => use defauld settings:\n",
    "        # url = URL — base page with table of movies;\n",
    "        # table_class='wikitable' — table on the page\n",
    "        if not url:\n",
    "            soup = get_soup(self.URL)\n",
    "        else:\n",
    "            soup = get_soup(url)\n",
    "\n",
    "        # find and return the desired table\n",
    "        table = soup.find('table', {'class':table_class})\n",
    "        return table\n",
    "    \n",
    "    \n",
    "    def parse_main_page(self, ) -> None:\n",
    "        \"\"\" Method for parsing the main page.\n",
    "            1) find the table\n",
    "            2) split the table by rows (extract all <tr> elements), each row = a film\n",
    "            3) parse each row (except the heading) - extract values: \n",
    "            3.1) find all table data <td> elements (table cells)\n",
    "            3.2) each <td> contains <th> - cell with film name (and film link but it is parsed separately)\n",
    "            3.3) assign values rank, peak, etc. (separate <td> elements)\n",
    "            4) parse values separately:\n",
    "            4.1) extract film title and get rid of some extra symbols\n",
    "            4.2) parse peak: get rid of <sup> elements using regex (because it was extracted as text from a cell)\n",
    "            4.3) compile the film url\n",
    "            4.4) turn revenue (box_office) into a number\n",
    "            5) form the dictionary\n",
    "        \"\"\"\n",
    "        # 1) and 2) steps\n",
    "        films_rank_table = self.find_table(self.URL, 'wikitable')\n",
    "        rows = films_rank_table.find_all('tr')[1:]\n",
    "        films = []\n",
    "        # 3)\n",
    "        for row in rows:\n",
    "            tds = row.find_all('td')  # table data\n",
    "            film_field = row.select_one('th')\n",
    "            rank, peak, box_office, year = tds[0].text.strip(), tds[1].text.strip(), tds[2].text.strip(), tds[3].text.strip() \n",
    "            \n",
    "            # 4)\n",
    "            name = film_field.text.strip()\n",
    "            acceptable_smbols = '012345678 .:&–'\n",
    "            name = ''.join([symbol for symbol in name if symbol.isalpha() or symbol in acceptable_smbols])\n",
    "\n",
    "            peak = re.sub(r'[A-Z]+\\d?', '', peak)\n",
    "\n",
    "            film_url = \"https://en.wikipedia.org/\" + row.find('i').find('a').get('href')\n",
    "            self.films_urls.append(film_url)\n",
    "            \n",
    "            \n",
    "            box_office = re.findall('\\$.{0,20}', box_office)[0]\n",
    "            box_office = int(re.sub(',', '', box_office[1:]))\n",
    "            \n",
    "            # 5)\n",
    "            films.append({\n",
    "                'name':name,\n",
    "                'year':int(year),\n",
    "                'rank':int(rank),\n",
    "                'peak':int(peak),\n",
    "                'revenue':box_office,\n",
    "                'wiki_page': film_url,\n",
    "            })\n",
    "        self.films = films\n",
    "    \n",
    "\n",
    "    def parse_films(self) -> None:\n",
    "        \"\"\" Method for parsing each film separately.\n",
    "            self.films - list of dictionaries\n",
    "            Use of self.parse_film_page()\n",
    "        \"\"\"  \n",
    "        for film in self.films:\n",
    "            film['director'] = []\n",
    "            film['country'] = []\n",
    "            film['poster'] = None\n",
    "            url = film['wiki_page']\n",
    "            self.parse_film_page(url, film)\n",
    "\n",
    "\n",
    "    def parse_film_page(self, url:str, film: dict) -> None:\n",
    "        \"\"\" Method for parsing a film page.\n",
    "        Args:\n",
    "            url (str): film url\n",
    "            film (dict): dictionary of already collected data for a film (from the main page)\n",
    "        \"\"\"\n",
    "        # find the table 'infobox vevent' on the page (a column on the right side of a page)\n",
    "        # and split it into rows (get rid of the 1st one containing film name)\n",
    "        film_info = self.find_table(url, 'infobox vevent')\n",
    "        rows = film_info.find_all('tr')[1:]\n",
    "\n",
    "        # iterate over each row\n",
    "        for i,row in enumerate(rows):\n",
    "            if i == 0:\n",
    "                # case for the film's poster, will be parsed later\n",
    "                continue\n",
    "\n",
    "            # find heading - row's heading or the name of a section\n",
    "            heading = row.find('th')\n",
    "            if heading is None:\n",
    "                # the problem solution for the Ne Zha 2 film\n",
    "                # several rows contain empty <th> and they are empty itself\n",
    "                continue\n",
    "            \n",
    "            # get text and row cells data (<td>)\n",
    "            # the table has 2 columns, thus there is only 1 <td>\n",
    "            heading = heading.text\n",
    "            data = row.find('td')\n",
    "\n",
    "            # parse the director\n",
    "            if heading == 'Directed by':\n",
    "                # several films are produced by several directors\n",
    "                # they are listed in <ul>\n",
    "                li = data.find('li')\n",
    "                if li is None:\n",
    "                    # if there is no list => doesn't mean there is only 1 director\n",
    "                    # sometimes they are \"listed\" with <br> tag\n",
    "                    # parse hard cases with </br>\n",
    "                    if data.find('br'):\n",
    "                        directors = list(data.stripped_strings)                         # find text and keep formatting\n",
    "                        directors = [self.clean_str(string) for string in directors]    # go through each string and clean it\n",
    "                        film['director'] = directors                                    # assign the 'director' field\n",
    "                    else:\n",
    "                    # if no <br> tags just extract the text in the <a> tag\n",
    "                        film['director'] = [self.clean_str(data.find('a').text)]\n",
    "                else:\n",
    "                    # if there is a list in the data column:\n",
    "                    film['director'] = self.find_directors_in_lists(data)\n",
    "            \n",
    "            # parse the country\n",
    "            if heading in ['Country', 'Countries']:\n",
    "                # extract text from this field\n",
    "                countries = list(data.stripped_strings)\n",
    "                # there is a problem with coutries filed:\n",
    "                # it has a footnote next to countries names\n",
    "                # and this footnote is also a text\n",
    "                while '[' in countries:\n",
    "                    # extract countries' names and get rid of footnotes\n",
    "                    if countries.index('[') != 0:\n",
    "                        film['country'].append(countries[:countries.index('[')][0])\n",
    "                    countries = countries[countries.index('[') + 3:]\n",
    "                # countirs list becomes empty during the while loop\n",
    "                # if it is not, then there were no footnotes: assign this list to the 'country' field\n",
    "                if countries:\n",
    "                    film['country'] = countries\n",
    "        # parse the poster url\n",
    "        film['poster'] = self.get_image_url(rows[0])\n",
    "\n",
    "\n",
    "    def find_directors_in_lists(self, data: bs4.element.Tag) -> list:\n",
    "        \"\"\" Method for finding the directors in lists.\n",
    "        Args:\n",
    "            data (bs4.element.Tag): <td> elemement in a table\n",
    "        Returns:\n",
    "            list: list of directors\n",
    "        The problem with lists appeared when some film's <td> contains\n",
    "        a list <ul> containing one more list <ul> => nested lists.\n",
    "        I had to extract the INNER lists and their texts.\n",
    "        \"\"\"\n",
    "\n",
    "        directors = []\n",
    "        # while a list contains lists inside: \n",
    "        # reassign directors list (make it empty), \n",
    "        # extract text, add it to 'directors', and\n",
    "        # make data=ul\n",
    "        # if new data doesn't contain <ul> anymore, then the last extracted text is correct => return it\n",
    "        while data.find('ul') is not None:\n",
    "            ul = data.find('ul')\n",
    "            directors = []\n",
    "            li = ul.find_all('li')\n",
    "            for l in li:\n",
    "                # remove sup tag in the end of strings\n",
    "                text = self.clean_str(l.text)\n",
    "                directors.append(text)\n",
    "            data = ul\n",
    "        return directors\n",
    "    \n",
    "    \n",
    "    def clean_str(self, text: str) -> str:\n",
    "        \"\"\" Method for deleting footnotes [i]\n",
    "        Args:\n",
    "            text (str): text from which [i] must be deleted\n",
    "        Returns:\n",
    "            str: cleaned and stripped text\n",
    "        \"\"\"\n",
    "        return re.sub(r'\\[\\d\\]', '', text.strip())\n",
    "    \n",
    "    def get_image_url(self, row: bs4.element.Tag) -> str:\n",
    "        \"\"\" Method for finding the poster's url\n",
    "        Args:\n",
    "            row (bs4.element.Tag): row of a table, which contains poster url\n",
    "        Returns:\n",
    "            str: url of a poster\n",
    "        \"\"\"\n",
    "        return 'https:' + row.find('td').find('a').find('img').get('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = ParserWikiPage()\n",
    "# p.parse_film_page('https://en.wikipedia.org/wiki/Avatar_(2009_film)', {'director':[], 'country':[]})\n",
    "# p.parse_film_page('https://en.wikipedia.org/wiki/Captain_America:_Civil_War', {'director':[], 'country':[]})\n",
    "# p.parse_film_page('https://en.wikipedia.org/wiki/Moana_2', {'director':[], 'country':[]})\n",
    "# p.parse_film_page('https://en.wikipedia.org/wiki/Furious_7', {'director':[], 'country':[]})\n",
    "# p.parse_film_page('https://en.wikipedia.org/wiki/Barbie_(film)', {'director':[], 'country':[]})\n",
    "# p.parse_film_page('https://en.wikipedia.org/wiki/Captain_Marvel_(film)', {'director':[], 'country':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ParserWikiPage()\n",
    "parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Avatar',\n",
       "  'year': 2009,\n",
       "  'rank': 1,\n",
       "  'peak': 1,\n",
       "  'revenue': 2923706026,\n",
       "  'wiki_page': 'https://en.wikipedia.org//wiki/Avatar_(2009_film)',\n",
       "  'director': ['James Cameron'],\n",
       "  'country': ['United Kingdom', 'United States'],\n",
       "  'poster': 'https://upload.wikimedia.org/wikipedia/en/thumb/d/d6/Avatar_%282009_film%29_poster.jpg/220px-Avatar_%282009_film%29_poster.jpg'},\n",
       " {'name': 'Avengers: Endgame',\n",
       "  'year': 2019,\n",
       "  'rank': 2,\n",
       "  'peak': 1,\n",
       "  'revenue': 2797501328,\n",
       "  'wiki_page': 'https://en.wikipedia.org//wiki/Avengers:_Endgame',\n",
       "  'director': ['Anthony Russo', 'Joe Russo'],\n",
       "  'country': ['United States'],\n",
       "  'poster': 'https://upload.wikimedia.org/wikipedia/en/0/0d/Avengers_Endgame_poster.jpg'},\n",
       " {'name': 'Avatar: The Way of Water',\n",
       "  'year': 2022,\n",
       "  'rank': 3,\n",
       "  'peak': 3,\n",
       "  'revenue': 2320250281,\n",
       "  'wiki_page': 'https://en.wikipedia.org//wiki/Avatar:_The_Way_of_Water',\n",
       "  'director': ['James Cameron'],\n",
       "  'country': ['United States'],\n",
       "  'poster': 'https://upload.wikimedia.org/wikipedia/en/thumb/5/54/Avatar_The_Way_of_Water_poster.jpg/220px-Avatar_The_Way_of_Water_poster.jpg'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.films[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_config = {\n",
    "    'dbname': 'wiki',\n",
    "    'user': 'superuser',\n",
    "    'password': '12345678',\n",
    "    'host': 'localhost',\n",
    "    'port': 5432\n",
    "}\n",
    "\n",
    "# connect to the 'wiki' database and create a cursor - for commands execution\n",
    "try:\n",
    "    connection = psycopg2.connect(**db_config)\n",
    "    print(\"connected\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in connection: {e}\")\n",
    "    exit()\n",
    "\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'films' created or already exists.\n"
     ]
    }
   ],
   "source": [
    "# create the 'films' table\n",
    "try:\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS films (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            title TEXT NOT NULL,\n",
    "            year INTEGER,\n",
    "            directors JSONB,\n",
    "            revenue REAL,\n",
    "            country JSONB,\n",
    "            poster TEXT\n",
    "        )\n",
    "    ''')    \n",
    "    connection.commit()\n",
    "    print(\"Table 'films' created or already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Avatar', 2009, ['James Cameron'], 2923.706, ['United Kingdom', 'United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/d/d6/Avatar_%282009_film%29_poster.jpg/220px-Avatar_%282009_film%29_poster.jpg')\n",
      "(2, 'Avengers: Endgame', 2019, ['Anthony Russo', 'Joe Russo'], 2797.5012, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/0/0d/Avengers_Endgame_poster.jpg')\n",
      "(3, 'Avatar: The Way of Water', 2022, ['James Cameron'], 2320.2502, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/5/54/Avatar_The_Way_of_Water_poster.jpg/220px-Avatar_The_Way_of_Water_poster.jpg')\n",
      "(4, 'Titanic', 1997, ['James Cameron'], 2257.8445, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/1/18/Titanic_%281997_film%29_poster.png')\n",
      "(5, 'Star Wars: The Force Awakens', 2015, ['J. J. Abrams'], 2068.2236, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/a/a2/Star_Wars_The_Force_Awakens_Theatrical_Poster.jpg')\n",
      "(6, 'Avengers: Infinity War', 2018, ['Anthony Russo', 'Joe Russo'], 2048.3599, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/4/4d/Avengers_Infinity_War_poster.jpg')\n",
      "(7, 'Ne Zha 2 ', 2025, ['Jiaozi'], 1963.9425, ['China'], 'https://upload.wikimedia.org/wikipedia/en/thumb/b/b6/Ne_Zha_2_poster.jpg/220px-Ne_Zha_2_poster.jpg')\n",
      "(8, 'SpiderMan: No Way Home', 2021, ['Jon Watts'], 1922.5988, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/0/00/Spider-Man_No_Way_Home_poster.jpg/220px-Spider-Man_No_Way_Home_poster.jpg')\n",
      "(9, 'Inside Out 2', 2024, ['Kelsey Mann'], 1698.8638, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/f/f7/Inside_Out_2_poster.jpg/220px-Inside_Out_2_poster.jpg')\n",
      "(10, 'Jurassic World', 2015, ['Colin Trevorrow'], 1671.5375, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/6/6e/Jurassic_World_poster.jpg/220px-Jurassic_World_poster.jpg')\n",
      "(11, 'The Lion King', 2019, ['Jon Favreau'], 1656.9434, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/9/9d/Disney_The_Lion_King_2019.jpg')\n",
      "(12, 'The Avengers', 2012, ['Joss Whedon'], 1518.8156, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/8/8a/The_Avengers_%282012_film%29_poster.jpg')\n",
      "(13, 'Furious 7', 2015, ['James Wan'], 1515.3414, ['United States', 'China'], 'https://upload.wikimedia.org/wikipedia/en/thumb/b/b8/Furious_7_poster.jpg/220px-Furious_7_poster.jpg')\n",
      "(14, 'Top Gun: Maverick', 2022, ['Joseph Kosinski'], 1495.6963, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/1/13/Top_Gun_Maverick_Poster.jpg/220px-Top_Gun_Maverick_Poster.jpg')\n",
      "(15, 'Frozen 2', 2019, ['Chris Buck', 'Jennifer Lee'], 1450.027, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/8/89/Frozen_II_%282019_animated_film%29.jpg/220px-Frozen_II_%282019_animated_film%29.jpg')\n",
      "(16, 'Barbie', 2023, ['Greta Gerwig'], 1447.0385, ['United States', 'United Kingdom'], 'https://upload.wikimedia.org/wikipedia/en/0/0b/Barbie_2023_poster.jpg')\n",
      "(17, 'Avengers: Age of Ultron', 2015, ['Joss Whedon'], 1402.8096, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/f/ff/Avengers_Age_of_Ultron_poster.jpg')\n",
      "(18, 'The Super Mario Bros. Movie', 2023, ['Aaron Horvath', 'Michael Jelenic'], 1362.567, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/4/44/The_Super_Mario_Bros._Movie_poster.jpg/220px-The_Super_Mario_Bros._Movie_poster.jpg')\n",
      "(19, 'Black Panther', 2018, ['Ryan Coogler'], 1347.2809, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/d/d6/Black_Panther_%28film%29_poster.jpg')\n",
      "(20, 'Harry Potter and the Deathly Hallows – Part 2', 2011, ['David Yates'], 1342.1398, ['United Kingdom', 'United States'], 'https://upload.wikimedia.org/wikipedia/en/d/df/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2.jpg')\n",
      "(21, 'Deadpool & Wolverine', 2024, ['Shawn Levy'], 1338.0736, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/4/4c/Deadpool_%26_Wolverine_poster.jpg/220px-Deadpool_%26_Wolverine_poster.jpg')\n",
      "(22, 'Star Wars: The Last Jedi', 2017, ['Rian Johnson'], 1332.5399, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/7/7f/Star_Wars_The_Last_Jedi.jpg')\n",
      "(23, 'Jurassic World: Fallen Kingdom', 2018, ['J. A. Bayona'], 1308.4734, ['China', 'United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/c/c6/Jurassic_World_Fallen_Kingdom.png/220px-Jurassic_World_Fallen_Kingdom.png')\n",
      "(24, 'Frozen', 2013, ['Chris Buck', 'Jennifer Lee'], 1290.0, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/0/05/Frozen_%282013_film%29_poster.jpg/220px-Frozen_%282013_film%29_poster.jpg')\n",
      "(25, 'Beauty and the Beast', 2017, ['Bill Condon'], 1263.5211, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/d/d6/Beauty_and_the_Beast_2017_poster.jpg')\n",
      "(26, 'Incredibles 2', 2018, ['Brad Bird'], 1242.8054, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/1/1f/Incredibles_2_%282018_animated_film%29.jpg/220px-Incredibles_2_%282018_animated_film%29.jpg')\n",
      "(27, 'The Fate of the Furious', 2017, ['F. Gary Gray'], 1238.7648, ['United States', 'China'], 'https://upload.wikimedia.org/wikipedia/en/thumb/2/2d/The_Fate_of_The_Furious_Theatrical_Poster.jpg/220px-The_Fate_of_The_Furious_Theatrical_Poster.jpg')\n",
      "(28, 'Iron Man 3', 2013, ['Shane Black'], 1214.8113, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/1/19/Iron_Man_3_poster.jpg')\n",
      "(29, 'Minions', 2015, ['Pierre Coffin', 'Kyle Balda'], 1159.4447, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/1/19/Minions_%282015_film%29.jpg')\n",
      "(30, 'Captain America: Civil War', 2016, ['Anthony Russo', 'Joe Russo'], 1153.3375, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/5/53/Captain_America_Civil_War_poster.jpg')\n",
      "(31, 'Aquaman', 2018, ['James Wan'], 1148.5284, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/e/ed/Aquaman_%28film%29_poster.jpg')\n",
      "(32, 'The Lord of the Rings: The Return of the King', 2003, ['Peter Jackson'], 1147.9974, ['New Zealand', 'Germany', 'United States'], 'https://upload.wikimedia.org/wikipedia/en/4/48/Lord_Rings_Return_King.jpg')\n",
      "(33, 'SpiderMan: Far From Home', 2019, ['Jon Watts'], 1132.6797, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/b/bd/Spider-Man_Far_From_Home_poster.jpg')\n",
      "(34, 'Captain Marvel', 2019, ['Anna Boden', 'Ryan Fleck'], 1128.2748, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/4/4e/Captain_Marvel_%28film%29_poster.jpg')\n",
      "(35, 'Transformers: Dark of the Moon', 2011, ['Michael Bay'], 1123.7941, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/b/bf/Transformers_dark_of_the_moon_ver5.jpg/220px-Transformers_dark_of_the_moon_ver5.jpg')\n",
      "(36, 'Skyfall', 2012, ['Sam Mendes'], 1108.5941, ['United Kingdom', 'United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/a/a7/Skyfall_poster.jpg/220px-Skyfall_poster.jpg')\n",
      "(37, 'Transformers: Age of Extinction', 2014, ['Michael Bay'], 1104.0541, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/0/0f/Transformers_Age_of_Extinction_poster.jpg/220px-Transformers_Age_of_Extinction_poster.jpg')\n",
      "(38, 'The Dark Knight Rises', 2012, ['Christopher Nolan'], 1081.1698, ['United States', 'United Kingdom'], 'https://upload.wikimedia.org/wikipedia/en/8/83/Dark_knight_rises_poster.jpg')\n",
      "(39, 'Joker', 2019, ['Todd Phillips'], 1074.4583, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/e/e1/Joker_%282019_film%29_poster.jpg/220px-Joker_%282019_film%29_poster.jpg')\n",
      "(40, 'Star Wars: The Rise of Skywalker', 2019, ['J. J. Abrams'], 1074.1443, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/a/af/Star_Wars_The_Rise_of_Skywalker_poster.jpg')\n",
      "(41, 'Toy Story 4', 2019, ['Josh Cooley'], 1073.3947, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/4/4c/Toy_Story_4_poster.jpg')\n",
      "(42, 'Toy Story 3', 2010, ['Lee Unkrich'], 1066.9708, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/6/69/Toy_Story_3_poster.jpg')\n",
      "(43, 'Pirates of the Caribbean: Dead Mans Chest', 2006, ['Gore Verbinski'], 1066.1797, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/2/2d/Pirates_of_the_caribbean_2_poster_b.jpg/220px-Pirates_of_the_caribbean_2_poster_b.jpg')\n",
      "(44, 'Rogue One: A Star Wars Story', 2016, ['Gareth Edwards'], 1057.4204, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/d/d4/Rogue_One%2C_A_Star_Wars_Story_poster.png/220px-Rogue_One%2C_A_Star_Wars_Story_poster.png')\n",
      "(45, 'Moana 2 ', 2024, ['David Derrick Jr.', 'Jason Hand', 'Dana Ledoux Miller'], 1053.5782, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/7/73/Moana_2_poster.jpg/220px-Moana_2_poster.jpg')\n",
      "(46, 'Aladdin', 2019, ['Guy Ritchie'], 1050.694, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/9/9a/Aladdin_%28Official_2019_Film_Poster%29.png')\n",
      "(47, 'Star Wars: Episode I – The Phantom Menace', 1999, ['George Lucas'], 1046.5154, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/4/40/Star_Wars_Phantom_Menace_poster.jpg/220px-Star_Wars_Phantom_Menace_poster.jpg')\n",
      "(48, 'Pirates of the Caribbean: On Stranger Tides', 2011, ['Rob Marshall'], 1045.7137, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/5/5e/Pirates_of_the_Caribbean_-_On_Stranger_Tides.png/220px-Pirates_of_the_Caribbean_-_On_Stranger_Tides.png')\n",
      "(49, 'Jurassic Park', 1993, ['Steven Spielberg'], 1037.5353, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/e/e7/Jurassic_Park_poster.jpg')\n",
      "(50, 'Despicable Me 3', 2017, ['Pierre Coffin', 'Kyle Balda'], 1034.8002, ['United States'], 'https://upload.wikimedia.org/wikipedia/en/thumb/8/80/Despicable_Me_3_theatrical_release_poster.jpg/220px-Despicable_Me_3_theatrical_release_poster.jpg')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# insert data\n",
    "def insert_film(cursor, title, year, director, revenue, country, poster):\n",
    "    cursor.execute('''\n",
    "        INSERT INTO films (title, year, directors, revenue, country, poster)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    ''', (title, year, director, revenue/1_000_000, country, poster))\n",
    "    connection.commit()\n",
    "\n",
    "\n",
    "for film in parser.films:\n",
    "    insert_film(cursor, \n",
    "                film['name'], \n",
    "                film['year'], \n",
    "                json.dumps(film['director']), \n",
    "                film['revenue'], \n",
    "                json.dumps(film['country']), \n",
    "                film['poster'])\n",
    "\n",
    "\n",
    "# check the correctness\n",
    "cursor.execute('SELECT * FROM films')\n",
    "films = cursor.fetchall()\n",
    "for film in films:\n",
    "    print(film)\n",
    "\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute('''\n",
    "#     DROP TABLE films\n",
    "# ''')\n",
    "# connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
